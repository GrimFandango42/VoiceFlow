# VoiceFlow - Local Voice Transcription System

[![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)](https://github.com/GrimFandango42/voiceflow)
[![Version](https://img.shields.io/badge/Version-v3.0.0-blue)](https://github.com/GrimFandango42/voiceflow/releases)
[![Security](https://img.shields.io/badge/Security-Audited-green)](https://github.com/GrimFandango42/voiceflow)
[![Testing](https://img.shields.io/badge/Testing-Comprehensive-brightgreen)](https://github.com/GrimFandango42/voiceflow)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

A local voice transcription system built on OpenAI Whisper with optional AI text enhancement. Designed for privacy-conscious users who require offline processing with no data transmission to external services.

## Overview

VoiceFlow provides real-time speech-to-text transcription using OpenAI Whisper models with local processing. The system automatically injects transcribed text at the cursor position in any application.

### Key Features
- **Local Processing** - All transcription happens on-device with no external API calls
- **Cross-Application** - Works in browsers, IDEs, text editors, and chat applications  
- **GPU Acceleration** - CUDA optimization with automatic CPU fallback
- **AI Text Enhancement** - Optional integration with local AI models (Ollama) for formatting
- **Two Deployment Options** - Minimal personal version or full enterprise version
- **Security Tested** - Comprehensive security audit with input validation

## Deployment Options

VoiceFlow provides two implementations optimized for different use cases:

### VoiceFlow Personal
Minimal implementation optimized for individual use with maximum privacy and performance.

```bash
# Quick setup
python run_personal.py

# Manual installation
pip install -r requirements_personal.txt
python voiceflow_personal.py
```

**Characteristics:**
- **Dependencies**: 4 packages (RealtimeSTT, pyautogui, keyboard, requests)
- **Memory Usage**: 150-250MB baseline
- **Startup Time**: 2-3 seconds
- **Storage**: Memory-only, no persistent data
- **Security**: Input validation, rate limiting, injection prevention
- **Code Size**: ~2,000 lines

### VoiceFlow Enterprise
Full-featured implementation with enterprise security, monitoring, and team collaboration features.

```bash
# Installation
pip install -r python/requirements.txt

# Run modes
python voiceflow_simple.py    # CLI mode
python voiceflow_tray.py      # System tray mode
```

**Characteristics:**
- **Dependencies**: 25+ packages with full feature set
- **Memory Usage**: 400-600MB with all features
- **Startup Time**: 8-12 seconds
- **Storage**: Optional encrypted database
- **Security**: Authentication, authorization, audit logging
- **Code Size**: ~15,000 lines with testing framework
## Performance Metrics

| Metric | Personal | Enterprise | Notes |
|--------|----------|------------|-------|
| Startup Time | 2-3s | 8-12s | Personal skips feature loading |
| Memory Usage | 150-250MB | 400-600MB | Personal has minimal dependencies |
| Transcription Latency | 150-250ms | 300-500ms | Personal uses optimized pipeline |
| Dependencies | 4 packages | 25+ packages | Personal excludes testing/monitoring |
| Storage Footprint | Memory only | Database + logs | Personal is ephemeral |

## Basic Operation

### VoiceFlow Personal
1. Start: `python run_personal.py`
2. Activate: Speak normally (auto-detection) or use Ctrl+Alt hotkey
3. Output: Transcribed text appears at cursor position

### VoiceFlow Enterprise  
1. Start: `python voiceflow_simple.py` (CLI) or `python voiceflow_tray.py` (background)
2. Position: Click in target text field
3. Activate: Press Ctrl+Alt and speak
4. Output: Enhanced text with optional logging/history

## Technical Features

### Speech Processing
- **Whisper Integration** - OpenAI Whisper models (tiny/base/small/large)
- **GPU Acceleration** - CUDA optimization with automatic CPU fallback
- **Voice Activity Detection** - Automatic speech start/stop detection
- **Real-time Processing** - Configurable latency vs accuracy trade-offs
- **Multi-language Support** - Language detection and model selection

### Text Enhancement
- **AI Integration** - Optional Ollama integration for text formatting
- **Context Awareness** - Punctuation and capitalization correction
- **Caching System** - Local enhancement cache for repeated phrases
- **Fallback Formatting** - Basic formatting when AI is unavailable

### Security Implementation
- **Input Validation** - Pattern-based injection prevention
- **Rate Limiting** - Configurable request throttling
- **Memory Management** - Automatic cleanup and bounded memory usage
- **Access Controls** - Enterprise version includes authentication/authorization
- **Audit Logging** - Optional comprehensive logging (Enterprise only)

## Architecture

The system uses a modular architecture with clear separation between transcription, enhancement, and security components:

```
voiceflow/
# Personal Version (Ultra-Fast)
‚îú‚îÄ‚îÄ voiceflow_personal.py      # üöÄ NEW: Ultra-fast personal version
‚îú‚îÄ‚îÄ run_personal.py            # üöÄ NEW: Smart launcher with auto-setup  
‚îú‚îÄ‚îÄ requirements_personal.txt  # üöÄ NEW: Minimal dependencies (4 packages)
‚îú‚îÄ‚îÄ PERSONAL_USAGE_GUIDE.md    # üöÄ NEW: Personal version guide

# Enterprise Version (Full-Featured)
‚îú‚îÄ‚îÄ core/                      # Core functionality modules
‚îÇ   ‚îú‚îÄ‚îÄ voiceflow_core.py     # Main speech processing engine
‚îÇ   ‚îú‚îÄ‚îÄ ai_enhancement.py     # AI text enhancement
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py           # Module exports
‚îú‚îÄ‚îÄ implementations/           # Application implementations
‚îÇ   ‚îú‚îÄ‚îÄ simple.py             # Simple CLI implementation
‚îú‚îÄ‚îÄ utils/                     # Shared utilities & security
‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ auth.py               # Authentication system
‚îÇ   ‚îú‚îÄ‚îÄ validation.py         # Input validation & security
‚îÇ   ‚îú‚îÄ‚îÄ rate_limiter.py       # Rate limiting protection
‚îÇ   ‚îî‚îÄ‚îÄ secure_db.py          # Encrypted database
‚îú‚îÄ‚îÄ python/                    # Server implementations
‚îÇ   ‚îî‚îÄ‚îÄ stt_server.py         # WebSocket server with security
‚îú‚îÄ‚îÄ tests/                     # Comprehensive testing suite (45+ files)
‚îú‚îÄ‚îÄ docs/                      # Documentation
‚îî‚îÄ‚îÄ security reports/          # Security audit results
```

## Configuration

### Environment Variables
```bash
# Core settings
export VOICEFLOW_MODEL=base          # Whisper model (tiny/base/small/large)
export VOICEFLOW_DEVICE=auto         # Processing device (auto/cuda/cpu)

# AI enhancement (optional)
export OLLAMA_HOST=localhost         # Ollama server host
export AI_MODEL=llama3.3:latest      # Enhancement model

# Security
export MAX_AUDIO_DURATION=30         # Maximum recording length (seconds)
```

### Configuration File
Optional configuration file at `~/.voiceflow/config.json`:
```json
{
  "audio": {
    "model": "base",
    "device": "auto", 
    "language": "en"
  },
  "ai": {
    "enabled": true,
    "temperature": 0.3
  }
}
```

## Additional Implementations

### WebSocket Server (Enterprise)
For web application integration:
```bash
python python/stt_server.py
```

### MCP Integration (Enterprise)
For Claude MCP ecosystem:
```bash
python voiceflow_mcp_server.py
```

## Testing (Enterprise)

The Enterprise version includes comprehensive testing framework:

```bash
# Run test suite
python run_tests.py

# Specific test types
python run_tests.py unit integration security
```

Test coverage includes unit tests, integration tests, security validation, and performance benchmarks.

## System Requirements

### Minimum
- **RAM**: 4GB available
- **CPU**: Modern multi-core processor
- **Python**: 3.8+
- **Storage**: 2GB for models

### Recommended  
- **RAM**: 8GB available
- **GPU**: NVIDIA GPU with 2GB+ VRAM for acceleration
- **Python**: 3.9+
- **Storage**: 5GB for multiple models

### Performance Characteristics
- **Transcription Latency**: 150-500ms depending on model and hardware
- **Accuracy**: 90-95% for clear speech
- **CPU Usage**: 10-30% during active transcription
- **Memory Growth**: Bounded with automatic cleanup

## Security

Both versions implement security best practices:

- **Input Validation**: Pattern-based injection prevention
- **Rate Limiting**: Configurable request throttling  
- **Memory Safety**: Bounded memory usage with automatic cleanup
- **Local Processing**: No external API calls required
- **Dependency Management**: Regular security updates

See [SECURITY_AUDIT_REPORT.md](SECURITY_AUDIT_REPORT.md) for detailed security analysis.

## Documentation

- **[Personal Usage Guide](PERSONAL_USAGE_GUIDE.md)** - VoiceFlow Personal setup and usage
- **[Architecture Guide](docs/ARCHITECTURE.md)** - Technical architecture details  
- **[User Guide](docs/USER_GUIDE.md)** - Enterprise version usage
- **[Security Report](SECURITY_AUDIT_REPORT.md)** - Security audit results

## Troubleshooting

### Common Issues

**No transcription output**
- Verify microphone permissions and device selection
- Check audio input levels
- Test model loading: `python -c "import whisper; whisper.load_model('base')"`

**Performance issues**
- Use smaller model: `export VOICEFLOW_MODEL=tiny`
- Check GPU availability: `nvidia-smi` (if applicable)
- Monitor system resources during operation

**AI enhancement failures**  
- Verify Ollama installation: `curl http://localhost:11434/api/tags`
- Check model availability: `ollama list`
- Test without AI: disable enhancement in configuration

## Contributing

VoiceFlow is open source. See [Contributing Guide](docs/CONTRIBUTING.md) for development setup and guidelines.

### Development
```bash
git clone https://github.com/GrimFandango42/voiceflow.git
cd voiceflow
pip install -r requirements_testing.txt
python run_tests.py

# Make your changes and submit a pull request
```

## üéØ Use Cases

### For Developers
- **Code Documentation** - Dictate comments and documentation
- **Email & Chat** - Fast communication without typing
- **Bug Reports** - Quick issue descriptions and notes
- **Meeting Notes** - Capture discussions and decisions

### For Writers
- **Content Creation** - Draft articles, stories, and scripts
- **Note Taking** - Capture ideas and research notes
- **Editing** - Voice-driven editing and revisions
- **Transcription** - Convert interviews and recordings

### For Professionals
- **Business Communication** - Professional emails and messages
- **Presentations** - Draft slides and speaker notes
- **Reports** - Document creation and collaboration
- **Accessibility** - Voice input for users with mobility challenges

## üìä Comparison

| Feature | VoiceFlow | Wispr Flow | Talon | Dragon |
|---------|-----------|------------|-------|--------|
| **Privacy** | ‚úÖ 100% Local | ‚ùå Cloud | ‚úÖ Local | ‚ùå Cloud |
| **Cost** | ‚úÖ Free | ‚ùå $7/month | ‚ùå $15/month | ‚ùå $300+ |
| **Speed** | ‚úÖ <500ms | ‚ö†Ô∏è Variable | ‚úÖ Fast | ‚ö†Ô∏è Variable |
| **Accuracy** | ‚úÖ 95%+ | ‚úÖ High | ‚úÖ High | ‚úÖ High |
| **AI Enhancement** | ‚úÖ Local AI | ‚ùå Basic | ‚ùå Limited | ‚ùå Basic |
| **Open Source** | ‚úÖ MIT | ‚ùå Proprietary | ‚ùå Proprietary | ‚ùå Proprietary |
| **Customization** | ‚úÖ Full | ‚ùå Limited | ‚úÖ Extensive | ‚ö†Ô∏è Some |

## üìà Roadmap

### v2.1.0 (Next Release)
- [ ] Linux/macOS native support
- [ ] Real-time transcription display
- [ ] Custom hotkey configuration UI
- [ ] Audio device selection interface
- [ ] Multi-language auto-detection

### v2.2.0 (Future)
- [ ] Plugin architecture for STT engines
- [ ] WebUI for configuration management
- [ ] Mobile companion app
- [ ] Cloud sync (optional, encrypted)
- [ ] Team collaboration features

## üìú License

MIT License - Complete freedom to use, modify, and distribute.

See [LICENSE](LICENSE) for full details.

## üôè Acknowledgments

- **OpenAI Whisper** - State-of-the-art speech recognition
- **Ollama** - Local AI model hosting
- **RealtimeSTT** - Real-time speech processing
- **Contributors** - Community developers and testers

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/GrimFandango42/voiceflow/issues)
- **Discussions**: [GitHub Discussions](https://github.com/GrimFandango42/voiceflow/discussions)
- **Documentation**: [Project Wiki](https://github.com/GrimFandango42/voiceflow/wiki)

---

**Made with ‚ù§Ô∏è for developers, writers, and professionals who value privacy and performance.**

## üè∑Ô∏è Keywords

`voice-to-text` `speech-recognition` `whisper` `ai-transcription` `local-processing` `privacy-focused` `developer-tools` `productivity` `accessibility` `open-source` `free-software` `voice-input` `dictation` `speech-to-text` `transcription` `ai-enhancement` `real-time` `cross-platform` `secure` `enterprise-ready`